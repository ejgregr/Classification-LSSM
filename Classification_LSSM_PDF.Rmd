---
title: "Coastal clusters for the Local Seaweed Services Model"
author: "Edward Gregr"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output:
  pdf_document:
    keep_tex: true       # Keep intermediate LaTeX file for troubleshooting
    latex_engine: pdflatex # Specify the LaTeX engine (pdflatex, xelatex, or lualatex). This renders the pdf
    number_sections: true # Optional, if you want numbered sections
    toc: true             # Table of contents (optional)
    fig_caption: true     # Enable figure captions
fontsize: 11pt            # Set font size (optional)
geometry: margin=1in      # Set margins (optional)
header-includes:
  - \usepackage{booktabs} # for tables
  - \usepackage{pdflscape}
  - \usepackage{tocloft}
  - \usepackage{float} # for controlling placement of tables and figures
  - \usepackage{placeins} # for a cmd to keep text in place.
  - \setlength{\intextsep}{5pt} % Vertical space above & below [h] floats
  - \setlength{\textfloatsep}{5pt} % Vertical space below (above) [t] ([b]) floats
  - \setlength{\abovecaptionskip}{5pt}
  - \setlength{\belowcaptionskip}{5pt}
---

\newpage

\listoftables
\listoffigures

\newpage

# Introduction
This work follows the approach described in Gregr (2024a) where k-means is applied to DFO MSEA data to create a spatial structure to support marine use planning initiatives. In the absence of an empirical representation for data-poor species, clusters describing areas of similar environmental conditions to be used as a framework to collate existing information on the distribution of kelp and other nearshore benthic species. 

This application uses oceanographic predictors produced by an ocean circulation model (Bianucci et al. 20XX). These predictors describe average ocean conditions for the months of January and July. 

## Background
Romina prepared Laura's data for her classifications, which will be compared to SDMs.
See Gregr (2024a) for details on the methods and the k-means classification (move here eventually). 

# Data sources
The output from the Bianucci model has been pre-processed by Barbosa, who also used the 20 m DFO bathymetry to derive some physical predictors. She also explored the potential for nutrient estimates from LiveOcean (presumably from sattelite) but these did not match the in situ measurements *(what are the available in situ measurements?*. Wind is also included and was sourced from the Global Wind Atlas, which provides downscaled re-analysis data on 250 m square grid (more details at https://globalwindatlas.info/en/about/introduction).

# Methods
## Predictor preparation
The pool of potential predictors was large (n=53). These were pre-screened manually, by examining correlations across the 53 variables. For predictors that were correlated >=0.6, we chose those that were correlated with more than on other predictor, or those that were assumed to be more relevant to Nereocystis growth and survival (e.g., July predictors were retained over January predictors).

Bathymetric derivatives were not considered here, as preliminary performance tests showed very high leverage (e.g., aspect). However, we note that these high leverage variables could be used to partition the classification across classes of a predictor of interest. *Add substrate to partition analysis between hard and soft substrates.*

We followed the approach used by Barbosa et al. and masked the pre-selected predictors using bathymetry to limitthe  classification to < 40 m depth. This allowed the cluster analysis to focus on the photic zone. (However, experience in the region suggests nereo does not reach the surface from depths > 15 m, Barbosa, pers. comm.).

Pre-selected predictors were then clipped to a reduced spatial extent if desired (e.g., to avoid areas of questionable data). Predictors with high skewness identified and normalized as necessary. The results were then scaled (by dividing by the standard deviation) and centred, followed by a final check of correlations. Any additional correlations >= 0.6 led to the removal of one of them. 

Finally, the predictors were limited to cells containing a complete set of values. This was done after the data are cleaned because this filtering should be sampling from the prepared data. If done first, this screening would change the distributions of the predictors and influence the normalization process. 

## Cluster analysis
Skewnesss plots were used to suggest the number of clusters. Multiple analyses were generated with a different number of clusters and compared qualitatively. 

Clusters were generated from subsets sampled from the full data set, as the data can be quite large. Despite using a seed to ensure the same sub-sample is used, repeating a classification can still yield different results as the algorithm itself (independent of the seed) chooses a new starting point at random for each cluster whenever its run. Final clusters can be created for the subset data, or for the full data set. 

The working clusters were then examined in a variety of ways including:
1.	A heat map of the within cluster sum of squares. 
2.	Silhouette plots of the clusters 
Silhouette plots provide information on how observations fit their clusters. Generally, the higher the average width of each clusters the better. 
3.  PCA plots of the clusters
4.	violin plots showing the predictor contributions to each cluster


# Results 
## Predictor selection

From the initial set of 16 pre-screened predictors (Table 1), cross-correlations were further examined. 

Remaining cross-correlations included: *julST_min* with *julST_max*, *julBT_min*, and *julBSspd_max*. We removed *julST_min* and *julBT_min* as this allowed retention of the maximum bottom temperature along with the surface temperatures.

*julST_max* was also correlated with both *julSS_max* and *julSS_min*, which were correlated at the cutoff of 0.60. We dropped *julSS_min* and kept both max values in despite the high correlation.

*julBSpd_max* was correlated with *julSSpd_min* and *julST_min*. We removed it based on the assumption that retaining temperature at the surface was more important, and that the surface speed minimum would be a better indication of nutrient supply (or lack of) than bottom speed. 

Finally, *julBS_max* was correlated with *julBS_min* and *julBT_max*. These were the only bottom measures remaining in July, and with the bottom temperature minimum removed, we chose to retain *julBT_max* as a bottom value to compare with *janBT_min*, which together provide a useful, biological bracketing of kelp early development and summer water column heating. This meant dropping *julBS_max* and *julBS_min*, and relying on surface salinity measures in the classification. 

After dropping 5 predictors based on correlations, 10 potential predictors remained. Subsequently, we dropped *northness* as it was uniformly distributed across all clusters, leaving **9** potential predictors


<!-- 
-->


```{r, DescripTable, echo=FALSE, escape=FALSE}
library(knitr)

descrip_table <- data.frame(
  Process = c("Light", "Energy", "Exposure", "Surface Salinity, Bottom Salinity", "Surface temperature, Bottom temperature"),
  Predictor = c("Northness", "tidal_cur, julSSpd_ave, julBSpd_ave", "Wind", "julSS_min, julSS_ave, julBS_ave", "julST_ave, julST_max, julBT_ave, julBT_max"),
  Description = c(
    "Kelps are light-restricted, so northness provides a measure of available sunlight.",
    "Energy provides an indication of water flow and nutrient mixing.", 
    "Exposure can influence substrate and also provide and indicator of mixing",
    "Kelps do better in higher salinity waters, as salinity tends to be correlated with both cooler temperatures and increased nutrients.",
    "Kelps do better in cooler waters"
  )
)

kable(descrip_table, format = "latex", booktabs = TRUE, 
      caption = "TO BE COMPLETED: The initial set of 16 pre-screened predictors from the available from Barbosa et al. DFOâ€™s MSEA group for different potential drivers of kelp habitat suitability, and the rationale for their inclusion.")  %>%
  kable_styling() %>%
  column_spec(1, width = "1.3in", latex_column_spec = "p{1.3in}") %>% 
  column_spec(2, width = "1in", latex_column_spec = "p{1in}") %>% 
  column_spec(3, width = "3.8in", latex_column_spec = "p{3.8in}")     

```


## Predictor assessment



```{r CorrTables, results='asis', echo=FALSE, table.pos='t' }
# Caption is part of kable()
# Using global: cor_table 

y_low <- lower.tri(cor_table, diag = TRUE)
cor_table[ y_low ] <- NA
knitr::kable( cor_table, digits = 2, format = "latex", booktabs = TRUE, 
              caption = "Correlation matrix for assessing predictor cross-correlations") %>%
  kable_styling( latex_options = c("scale_down") ) %>% 
  row_spec(0, angle = 90) 
#%>% landscape()

x <- 0.6
high_rows <- apply(cor_table, 1, function(row) any(abs(row) > x, na.rm = TRUE))
z <- cor_table[ high_rows, ]
knitr::kable( z, digits = 2, format = "latex", booktabs = TRUE, 
              caption = "Predictor variables with 1 or more correlations that exceed 0.6 threshold") %>%
  kable_styling( latex_options = c("scale_down") ) %>% 
  row_spec(0, angle = 90) 
#%>% landscape()

```
\newpage
## Distributions and outliers
Skewness scores showed strong nonnormality for 4 predictors. Transforms were applied to *julBS_ave*, *julSS_min*, *julSSpd_ave*, and *tidal_cur*. Simple transforms were effective at reducing skewness to less than |1|, thus ceilings were not required (**Table 4**). 

```{r SkewTable, results='asis', echo=FALSE, table.pos='t'}

# Make the table to show change in skew after transform. 
sktab <- MakeSkewTable()

# Print the resulting table ...
# Would be nice to BOLD rows where skew is NOT equal. 
knitr::kable( sktab, format = "latex", booktabs = TRUE, 
              caption = "Transforms applied to skewed predictors and the resulting change in skewness.") %>%
kable_styling(latex_options = "hold_position")

```

Pre (Figure 1) and post (Figure 2) histograms showing the effects of the transformation and scaling of the data. 
\newpage
```{r preHists, echo=FALSE, fig.pos='h', fig.cap="Histograms of the selected, unmodified predictors.", fig.align='center', fig.width=8, fig.height=3.75}

# fig.pos='H', 
#```{r PreAndPostHists, echo=FALSE, include=FALSE, fig.pos='t', fig.cap= c("Histograms of the #selected, unmodified #Predictors.", "Histograms of selected, transformed, and scaled predictor #data."), out.extra='keepaspectratio', Fig.align='center'}

# Plot the first group of 8 histograms
par(mfrow = c(3, 6), mar = c(2, 2, 2, 2))

for (i in 1:dim(stack_data)[2]) {
  hist(stack_data[, i], nclass=50, main = colnames(stack_data)[i], xlab="")
}

```

<!-- \smallskip 
     \medskip -->
\bigskip

```{r transHists, echo=FALSE, fig.pos='b', fig.cap="Histograms of the selected, transformed, and scaled predictor data.", fig.align='center', fig.width=8, fig.height=3.75}

# Plot the second group of 8 histograms
par(mfrow = c(3, 6), mar = c(2, 2, 2, 2))

for (i in 1:dim(t_stack_data)[2]) {
  hist(t_stack_data[, i], nclass=50, main = colnames(t_stack_data)[i], xlab="")
}

```
\newpage
\FloatBarrier

# Cluster exploration

The number of clusters is informed by a scree plot (Figure 3). This plot compares the total within-cluster sum of squares (TWSS) for an increasing number of clusters. Scree plots show how the TWSS is reduced with each additional cluster. The optimal number of clusters is found near the elbow in the data (i.e., the point beyond which the reduction of TWSS becomes small with each additional cluster.

```{r ScreePlot,  warning=FALSE, message=FALSE, echo=FALSE, fig.cap="Scree plot showing the total within sum-of-squares across a range of cluster numbers."}
plotme
```

Repeated scree plots generated using subsamples (n=50,000) of complete cases provide more information than a scree plot of all the data. Based on a manual assessment of repeated plots, the number of clusters before the breakpoint varied between 6 and 10. The scree plot of all the data breaks at 8 (Figure 3).

Heat maps of the cluster standard deviations (Figure 4) show how the various predictor values are distributed among the clusters. 
```{r HeatMap, warning=FALSE, message=FALSE, echo=FALSE, fig.cap="Heat map showing within cluster standard deviation of the predictors.", fig.show='asis', fig.align='center',fig.width=6, fig.height=4}
z_heat
```

Silhouette plots show the width of the clusters and the total number of values (i.e., pixels) within each (Figure 5). Higher average silhouette width indicates a better fit with the number of clusters. 
```{r SilhouettePlot, warning=FALSE, message=FALSE, echo=FALSE, fig.cap="Silhouette plot showing pixel membership in each cluster and silhouette widths.", figure.placement='H', fig.align='center',fig.width=6, fig.height=4}
par(mar = c(5, 2, 0, 2)) 
plot(sk, col = 1:nclust, border=NA, main = "" )
```

\newpage
## Part 2 - Clusters and predictor loadings
While exercising the cluster analysis, northness was found to contribute equally to the clusters regardless of number of clusters. It was dropped to simplify the analysis. 

The PCA plots (Figure 6, Figure 7) show how the clusters are distributed across the first two (Figure 7) and second two (Figure 8) dimensions.

The loadings are quantified in Table 5, and shown graphically in Figure 8. 

\FloatBarrier
```{r PCATable, warning=FALSE, message=FALSE, echo=FALSE}

loads <- round( pca_results$loadings$rotation, 3 )
knitr::kable( loads, format = "latex", booktabs = TRUE, 
              caption = "Loadings of predictors onto the Principal Components of the clusters.") %>%
  kable_styling( latex_options = c("scale_down") )

```

\newpage
```{r PCAPlot1, warning=FALSE, message=FALSE, echo=FALSE, fig.cap="PCA Plots showing the clusters across the first and second dimensions.", fig.pos='t', fig.align='center',fig.width=6.5, fig.height=3.7}
par(mar = c(0, 0, 0, 0)) 
plot( pca_results$plot1 )
```

```{r PCAPlot2, warning=FALSE, message=FALSE, echo=FALSE, fig.cap="PCA Plots showing the clusters across the third and fourth dimensions.", fig.pos='b', fig.align='center', fig.width=6.5, fig.height=3.7}
par(mar = c(0, 0, 0, 0)) 
plot( pca_results$plot2 )
```

```{r ViolinPlot, warning=FALSE, message=FALSE, echo=FALSE, fig.cap="Violin plots showing distribution of predictors in each of the k-means clusters."}
vplots
```

<!-- Next Step: Include the corresponding TIF, rotated and full page! -->



<!-- THE END -->