---
title: "Coastal clusters for the Local Seaweed Services Model"
author: "Edward Gregr"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output:
  pdf_document:
    keep_tex: true       # Keep intermediate LaTeX file for troubleshooting
    latex_engine: pdflatex # Specify the LaTeX engine (pdflatex, xelatex, or lualatex). This renders the pdf
    number_sections: true # Optional, if you want numbered sections
    toc: true             # Table of contents (optional)
    fig_caption: true     # Enable figure captions
fontsize: 11pt            # Set font size (optional)
geometry: margin=1in      # Set margins (optional)
header-includes:
  - \usepackage{booktabs} # for tables
  - \usepackage{pdflscape}
  - \usepackage{tocloft}
  - \usepackage{float} # for controlling placement of tables and figures
  - \usepackage{placeins} # for a cmd to keep text in place.
  - \setlength{\intextsep}{5pt} % Vertical space above & below [h] floats
  - \setlength{\textfloatsep}{5pt} % Vertical space below (above) [t] ([b]) floats
  - \setlength{\abovecaptionskip}{5pt}
  - \setlength{\belowcaptionskip}{5pt}
---

\newpage

\listoftables
\listoffigures

\newpage

# Introduction
This work follows the approach described in Gregr (2024a) where k-means is applied to DFO MSEA data to create a spatial structure to support marine use planning initiatives. In the absence of an empirical representation for data-poor species, clusters describing areas of similar environmental conditions to be used as a framework to collate existing information on the distribution of kelp and other nearshore benthic species. 

This application uses oceanographic predictors produced by an ocean circulation model (Bianucci et al. 20XX). These predictors describe average ocean conditions for the months of January and July. 

## Background
Romina prepared Laura's data for her classifications, which will be compared to SDMs.
See Gregr (2024a) for details on the methods and the k-means classification (move here eventually). 

# Data sources
The output from the Bianucci model has been pre-processed by Barbosa, who also used the 20 m DFO bathymetry to derive some physical predictors. She also explored the potential for nutrient estimates from LiveOcean (presumably from sattelite) but these did not match the in situ measurements *(what are the available in situ measurements?*. Wind is also included and was sourced from the Global Wind Atlas, which provides downscaled re-analysis data on 250 m square grid (more details at https://globalwindatlas.info/en/about/introduction).

Barbosa used bathymetry as a mask to limit classification to < 40 m depth. However, experience in the region suggests nereo does not reach the surface from depths > 15 m (Romina, pers. comm.).

# Methods
##Predictor screening
The pool of potential predictors was large (n=53). These were pre-screened by examining correlations and preliminary performance in the k-means clusters. 

Following Barbosa et al., bathymetry was used to limit the analysis to suitable depths and allow the cluster analysis to focus on the photic zone. Bathymetric derivatives were not considered here, as preliminary performance tests showed very high leverage (e.g., aspect).

*Add substrate to partition analysis between hard and soft substrates.*

## Predictor preparation
Pre-selected predictors were then clipped to a reduced spatial extent if desired (e.g., to avoid areas of questionable data). Predictors with high skewness identified and normalized if necessary. The results were then scaled (by dividing by the standard deviation) and centred, followed by a final check of correlations. Where predictors were cross-correlated > 0.6, one of them is removed. 

Finally, the predictors are limited to cells where data exists for all predictors. This is done after the data are cleaned because the all-data filtering should be sampling from clean distributions of each predictor, not a driver of the cleaning. If you know what I mean.

## Cluster analysis
Skewnesss plots were used to suggest the number of clusters. Multiple analyses were generated with a different number of clusters and compared qualitatively. 

Clusters were generated from subsets sampled from the full data set, as the data can be quite large. Despite using a seed to ensure the same sub-sample is used, repeating a classification can still yield different results as the algorithm itself (independent of the seed) chooses a new starting point at random for each cluster whenever its run. Final clusters can be created for the subset data, or for the full data set. 

The working clusters were then examined in a variety of ways including:
1.	A heat map of the within cluster sum of squares. 
2.	Silhouette plots of the clusters 
Silhouette plots provide information on how observations fit their clusters. Generally, the higher the average width of each clusters the better. 
3.  PCA plots of the clusters
4.	violin plots showing the predictor contributions to each cluster


# Results 
##Selected predictors

The selected predictors (Table 1) ... 

```{r, DescripTable, echo=FALSE, escape=FALSE}
library(knitr)

descrip_table <- data.frame(
  Process = c("Light", "Energy", "Exposure", "Surface Salinity, Bottom Salinity", "Surface temperature, Bottom temperature"),
  Predictor = c("Northness", "tidal_cur, julSSpd_ave, julBSpd_ave", "Wind", "julSS_min, julSS_ave, julBS_ave", "julST_ave, julST_max, julBT_ave, julBT_max"),
  Description = c(
    "Kelps are light-restricted, so northness provides a measure of available sunlight.",
    "Energy provides an indication of water flow and nutrient mixing.", 
    "Exposure can influence substrate and also provide and indicator of mixing",
    "Kelps do better in higher salinity waters, as salinity tends to be correlated with both cooler temperatures and increased nutrients.",
    "Kelps do better in cooler waters"
  )
)

kable(descrip_table, format = "latex", booktabs = TRUE, 
      caption = "The predictors available from DFOâ€™s MSEA group for different potential drivers of kelp habitat suitability, and the rationale for their inclusion.")  %>%
  kable_styling() %>%
  column_spec(1, width = "1.3in", latex_column_spec = "p{1.3in}") %>% 
  column_spec(2, width = "1in", latex_column_spec = "p{1in}") %>% 
  column_spec(3, width = "3.8in", latex_column_spec = "p{3.8in}")     

```

##Selected predictors

# Results 

## Data description

The loaded (and potentially trimmed) raster stack is `r dim(tif_stack)[1]` by `r dim(tif_stack)[2]`, giving a total of `r scales::comma( dim(tif_stack)[1] * dim(tif_stack)[2])` pixels in the study domain. Much of this area is land, or deeper waters excluded by the bathymetry.

*Include: proportion nearshore, proportion of that with good substrate, and final sample size for clustering.* 

## Predictor assessment

### Cross-correlations
When cross-correlations exceeded 0.6 among the predictors (Table 2, Table 3), one of them was removed. Cross-correlations included: *julSSpd_ave* with *julBSpd_ave*, *julSS_ave* and *julSS_min*, and *julST_ave* and *julST_max*. Current speed at the surface was deemed more important than at the  bottom; minimum salinity more important than average salinity, and maximum SST more important than average. The predictors *julST_ave*, *julSS_ave*, *julBSpd_ave* were therefore dropped. Additionally, after initial explorations of clusters, *northness* was seen to constantly contribute equally across clusters and was thus also dropped. 

This left **8** potential predictors.

```{r Correlations, results='asis', echo=FALSE, table.pos='t' }
# Caption is part of kable()
# Using global: cor_table 

y_low <- lower.tri(cor_table, diag = TRUE)
cor_table[ y_low ] <- NA
knitr::kable( cor_table, digits = 2, format = "latex", booktabs = TRUE, 
              caption = "Correlation matrix for assessing predictor cross-correlations") %>%
  kable_styling( latex_options = c("scale_down") ) %>% 
  row_spec(0, angle = 90) 
#%>% landscape()

x <- 0.6
high_rows <- apply(cor_table, 1, function(row) any(row > x, na.rm = TRUE))
z <- cor_table[ high_rows, ]
knitr::kable( z, digits = 2, format = "latex", booktabs = TRUE, 
              caption = "Predictor variables with 1 or more correlations that exceed 0.6 threshold") %>%
  kable_styling( latex_options = c("scale_down") ) %>% 
  row_spec(0, angle = 90) 
#%>% landscape()

```
\newpage
## Distributions and outliers
Skewness scores showed strong nonnormality for 4 predictors. Transforms were applied to *julBS_ave*, *julSS_min*, *julSSpd_ave*, and *tidal_cur*. Simple transforms were effective at reducing skewness to less than |1|, thus ceilings were not required (**Table 4**). 

```{r SkewTable, results='asis', echo=FALSE, table.pos='t'}

skdat <- data.frame(Predictor = character(), Pre_Skew = numeric(), Post_Skew = numeric(), stringsAsFactors = FALSE)

# Loop through the columns of the dataset
for (i in 1:ncol(t_stack_data)) {
  # Calculate skewness for each column in both datasets
  pre  <- skewness(stack_data[, i], na.rm = TRUE) 
  post <- skewness(t_stack_data[, i], na.rm = TRUE) 
  
  # Combine the column name and skewness values into a new data frame row
  new_row <- data.frame(
    Predictor = colnames(t_stack_data)[i],  # Get column name
    Pre_Skew  = round(pre, 3),                     # Skewness before transformation
    Post_Skew = round(post, 3)                     # Skewness after transformation
  )
  # Append the new row to skdat
  skdat <- rbind(skdat, new_row)
}

# Now add the transform values 
# Create the data frame
# df <- data.frame(
#   Predictor = c("REI", "freshwater_index", "standard_dev_slope", "temp_range"),
#   Ceiling = c(0.3, 0.025, 10, NA),
#   Power_transform = c("1/2", "1/3", "1/2", "1/2")
# )
# Merge the data frames


# Print the resulting data frame
knitr::kable( skdat, format = "latex", booktabs = TRUE, 
              caption = "Transforms applied to skewed predictors and the resulting change in skewness.") %>%
kable_styling(latex_options = "hold_position")

```

Pre (Figure 1) and post (Figure 2) histograms showing the effects of the transformation and scaling of the data. 
\newpage
```{r preHists, echo=FALSE, fig.pos='h', fig.cap="Histograms of the selected, unmodified predictors.", fig.align='center', fig.width=8, fig.height=3.75}

# fig.pos='H', 
#```{r PreAndPostHists, echo=FALSE, include=FALSE, fig.pos='t', fig.cap= c("Histograms of the #selected, unmodified #Predictors.", "Histograms of selected, transformed, and scaled predictor #data."), out.extra='keepaspectratio', Fig.align='center'}

# Plot the first group of 8 histograms
par(mfrow = c(3, 6), mar = c(2, 2, 2, 2))

for (i in 1:dim(stack_data)[2]) {
  hist(stack_data[, i], nclass=50, main = colnames(stack_data_clean)[i], xlab="")
}

```

<!-- \smallskip 
     \medskip -->
\bigskip

```{r transHists, echo=FALSE, fig.pos='b', fig.cap="Histograms of the selected, transformed, and scaled predictor data.", fig.width=8, fig.height=3.75}

# Plot the second group of 8 histograms
par(mfrow = c(3, 6), mar = c(2, 2, 2, 2))

for (i in 1:dim(stack_data_clean)[2]) {
  hist(stack_data_clean[, i], nclass=50, main = colnames(t_stack_data)[i], xlab="")
}

```
\newpage
\FloatBarrier

# Cluster exploration

The number of clusters is informed by a scree plot (Figure 3). This plot compares the total within-cluster sum of squares (TWSS) for an increasing number of clusters. Scree plots show how the TWSS is reduced with each additional cluster. The optimal number of clusters is found near the elbow in the data (i.e., the point beyond which the reduction of TWSS becomes small with each additional cluster.

```{r ScreePlot,  warning=FALSE, message=FALSE, echo=FALSE, fig.cap="Scree plot showing the total within sum-of-squares across a range of cluster numbers."}
plotme
```

Repeated scree plots generated using subsamples (n=50,000) of complete cases provide more information than a scree plot of all the data. Based on a manual assessment of repeated plots, the number of clusters before the breakpoint varied between 6 and 10. The scree plot of all the data breaks at 8 (Figure 3).

Heat maps of the cluster standard deviations (Figure 4) show how the various predictor values are distributed among the clusters. 
```{r HeatMap, warning=FALSE, message=FALSE, echo=FALSE, fig.cap="Heat map showing within cluster standard deviation of the predictors.", fig.show='asis', fig.align='center',fig.width=6, fig.height=4}
z_heat
```

Silhouette plots show the width of the clusters and the total number of values (i.e., pixels) within each (Figure 5). Higher average silhouette width indicates a better fit with the number of clusters. 
```{r SilhouettePlot, warning=FALSE, message=FALSE, echo=FALSE, fig.cap="Silhouette plot showing pixel membership in each cluster and silhouette widths.", figure.placement='H', fig.align='center',fig.width=6, fig.height=4}
par(mar = c(5, 2, 0, 2)) 
plot(sk, col = 1:nclust, border=NA, main = "" )
```

\newpage
## Part 2 - Clusters and predictor loadings
While exercising the cluster analysis, northness was found to contribute equally to the clusters regardless of number of clusters. It was dropped to simplify the analysis. 

The PCA plots (Figure 6, Figure 7) show how the clusters are distributed across the first two (Figure 7) and second two (Figure 8) dimensions.

The loadings are quantified in Table 5, and shown graphically in Figure 8. 

\FloatBarrier
```{r PCATable, warning=FALSE, message=FALSE, echo=FALSE}

loads <- round( pca_results$loadings$rotation, 3 )
knitr::kable( loads, format = "latex", booktabs = TRUE, 
              caption = "Loadings of predictors onto the Principal Components of the clusters.") %>%
  kable_styling( latex_options = c("scale_down") )

```

\newpage
```{r PCAPlot1, warning=FALSE, message=FALSE, echo=FALSE, fig.cap="PCA Plots showing the clusters across the first and second dimensions.", fig.pos='t', fig.align='center',fig.width=6.5, fig.height=3.7}
par(mar = c(0, 0, 0, 0)) 
plot( pca_results$plot1 )
```

```{r PCAPlot2, warning=FALSE, message=FALSE, echo=FALSE, fig.cap="PCA Plots showing the clusters across the third and fourth dimensions.", fig.pos='b', fig.align='center', fig.width=6.5, fig.height=3.7}
par(mar = c(0, 0, 0, 0)) 
plot( pca_results$plot2 )
```

```{r ViolinPlot, warning=FALSE, message=FALSE, echo=FALSE, fig.cap="Violin plots showing distribution of predictors in each of the k-means clusters."}
vplots
```

<!-- Next Step: Include the corresponding TIF, rotated and full page! -->



<!-- THE END -->